{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e490b12a-0322-4ccf-b4be-c4029951f6f5",
   "metadata": {},
   "source": [
    "# Alumno: Daniel Rodriguez Amezaga "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc45fb-b901-4e9f-932d-eaf98207aee2",
   "metadata": {},
   "source": [
    "#### Leccion 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a1a26-e0f8-4ded-a37b-dcd4ca3b5473",
   "metadata": {},
   "source": [
    "#### Importamos SparkSession y StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "67eefd95-518a-4255-b678-301a111756a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09dd66-7e28-4b58-acad-970bf15c7635",
   "metadata": {},
   "source": [
    "#### Creamos la sesión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38c96e3d-326c-42df-b310-f691d6e239a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('iris').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e5312-87d8-4205-8285-195c6df8c8c4",
   "metadata": {},
   "source": [
    "#### Coloco el DataFrame en cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2d2efaa5-6d48-48b0-b511-0d8dd0747af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('Iris.csv', header = True).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b733e-4276-4464-8dd9-01d56c922be7",
   "metadata": {},
   "source": [
    "#### Visualizo el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e8d9a958-ebaa-4d18-8667-db9d2f560dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id SepalLengthCm SepalWidthCm PetalLengthCm PetalWidthCm         Species\n",
       "0      1           5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1      2           4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2      3           4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3      4           4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4      5           5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..   ...           ...          ...           ...          ...             ...\n",
       "145  146           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146  147           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147  148           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148  149           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149  150           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2302e4-a2b8-4354-b04f-acfa0a805008",
   "metadata": {},
   "source": [
    "#### Cuento las filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "85c340d6-05e5-4344-8023-bc2facb17b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f9e5-2518-4dea-8a70-e72c2f617c57",
   "metadata": {},
   "source": [
    "#### Visualizo las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "871f4602-d969-48e5-96bf-f772316a28da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'SepalLengthCm',\n",
       " 'SepalWidthCm',\n",
       " 'PetalLengthCm',\n",
       " 'PetalWidthCm',\n",
       " 'Species']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee12c1-c95f-4a07-9c48-7c6553ecdcf4",
   "metadata": {},
   "source": [
    "#### Muestro el tipo de dato de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5545780f-ff45-449b-ad9c-94a51891fcca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'string'),\n",
       " ('SepalLengthCm', 'string'),\n",
       " ('SepalWidthCm', 'string'),\n",
       " ('PetalLengthCm', 'string'),\n",
       " ('PetalWidthCm', 'string'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fb435-fff9-4aea-ac84-9c617628cff9",
   "metadata": {},
   "source": [
    "#### Visualizar los datos para llegar a entenderlos mejor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "36bfc062-c8f2-4d8a-863f-e9ab5b28ead7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>75.5</td>\n",
       "      <td>5.843333333333335</td>\n",
       "      <td>3.0540000000000007</td>\n",
       "      <td>3.7586666666666693</td>\n",
       "      <td>1.1986666666666672</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>43.445367992456916</td>\n",
       "      <td>0.8280661279778637</td>\n",
       "      <td>0.43359431136217375</td>\n",
       "      <td>1.764420419952262</td>\n",
       "      <td>0.7631607417008414</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>99</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                  Id       SepalLengthCm         SepalWidthCm  \\\n",
       "0   count                 150                 150                  150   \n",
       "1    mean                75.5   5.843333333333335   3.0540000000000007   \n",
       "2  stddev  43.445367992456916  0.8280661279778637  0.43359431136217375   \n",
       "3     min                   1                 4.3                  2.0   \n",
       "4     max                  99                 7.9                  4.4   \n",
       "\n",
       "        PetalLengthCm        PetalWidthCm         Species  \n",
       "0                 150                 150             150  \n",
       "1  3.7586666666666693  1.1986666666666672            None  \n",
       "2   1.764420419952262  0.7631607417008414            None  \n",
       "3                 1.0                 0.1     Iris-setosa  \n",
       "4                 6.9                 2.5  Iris-virginica  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74db38-41c8-4a99-a0e4-33d7b9aafe2e",
   "metadata": {},
   "source": [
    "#### Convierto los campos que me interesan a float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "86c460e6-f6f4-44c4-8f25-5af7819e2316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|\n",
      "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|\n",
      "| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|\n",
      "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|\n",
      "| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|\n",
      "| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|\n",
      "| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|\n",
      "| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|\n",
      "| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|\n",
      "| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "dataset = df.select(col('id'),\n",
    "                    col('SepalLengthCm').cast('double'),\n",
    "                    col('SepalWidthCm').cast('double'),\n",
    "                    col('PetalLengthCm').cast('double'),\n",
    "                    col('PetalWidthCm').cast('double'),\n",
    "                    col('species')\n",
    ")\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a62795-030d-480a-be8b-8dda7f42b6b9",
   "metadata": {},
   "source": [
    "#### Compruebo si el cambio se realizó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cbe44200-f357-499a-bd0a-d115f02cf527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('SepalLengthCm', 'double'),\n",
       " ('SepalWidthCm', 'double'),\n",
       " ('PetalLengthCm', 'double'),\n",
       " ('PetalWidthCm', 'double'),\n",
       " ('species', 'string')]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71cf87-8cbe-4e67-b92b-6239c63c7f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformar en vector los datos numéricos usando VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bc555b69-39be-470a-a3eb-2785d3d10036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    species|         features|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|[5.4,3.9,1.7,0.4]|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|[4.6,3.4,1.4,0.3]|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|[5.0,3.4,1.5,0.2]|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|[4.4,2.9,1.4,0.2]|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|[4.9,3.1,1.5,0.1]|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|[5.4,3.7,1.5,0.2]|\n",
      "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|[4.8,3.4,1.6,0.2]|\n",
      "| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|[4.8,3.0,1.4,0.1]|\n",
      "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|[4.3,3.0,1.1,0.1]|\n",
      "| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|[5.8,4.0,1.2,0.2]|\n",
      "| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|[5.7,4.4,1.5,0.4]|\n",
      "| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|[5.4,3.9,1.3,0.4]|\n",
      "| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|[5.1,3.5,1.4,0.3]|\n",
      "| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|[5.7,3.8,1.7,0.3]|\n",
      "| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|[5.1,3.8,1.5,0.3]|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numericCols = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
    "df = assembler.transform(dataset)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "be1da942-d070-4a1d-a5d0-32f2e3af77ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('SepalLengthCm', 'double'),\n",
       " ('SepalWidthCm', 'double'),\n",
       " ('PetalLengthCm', 'double'),\n",
       " ('PetalWidthCm', 'double'),\n",
       " ('species', 'string'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a0822-9582-433a-b752-edab54480cfa",
   "metadata": {},
   "source": [
    "# Transformar los datos correspondientes a la columna especies usando StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f6c394e6-16a4-4f87-9e7c-9f65f2a2fc96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------------+----------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    species|         features|species_by|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|[5.4,3.9,1.7,0.4]|       0.0|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|[4.6,3.4,1.4,0.3]|       0.0|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|[5.0,3.4,1.5,0.2]|       0.0|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|[4.4,2.9,1.4,0.2]|       0.0|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|[5.4,3.7,1.5,0.2]|       0.0|\n",
      "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|[4.8,3.4,1.6,0.2]|       0.0|\n",
      "| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|[4.8,3.0,1.4,0.1]|       0.0|\n",
      "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|[4.3,3.0,1.1,0.1]|       0.0|\n",
      "| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|[5.8,4.0,1.2,0.2]|       0.0|\n",
      "| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|[5.7,4.4,1.5,0.4]|       0.0|\n",
      "| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|[5.4,3.9,1.3,0.4]|       0.0|\n",
      "| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|[5.1,3.5,1.4,0.3]|       0.0|\n",
      "| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|[5.7,3.8,1.7,0.3]|       0.0|\n",
      "| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|[5.1,3.8,1.5,0.3]|       0.0|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "dataset = StringIndexer(inputCol = 'species', outputCol = 'species_by')\n",
    "df = dataset.fit(df).transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef716eef-20f0-4944-b9a9-6ffb0574cd14",
   "metadata": {},
   "source": [
    "# Calcular la predicción y la precisión del modelo empleando Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939daebe-5bc3-43be-aeb8-b282a562fb09",
   "metadata": {},
   "source": [
    "#### Dividir nuestro conjunto de datos en datos de entrenamiento y datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5fd7ce7c-f2bf-4d8f-9482-701431d18c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 103\n",
      "Test Dataset Count: 47\n"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a4d147f3-2b0f-48a3-89bd-a8079796b95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol='species_by', \n",
    "                            featuresCol='features', \n",
    "                            maxDepth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "57abb1d2-b05c-41e3-8f72-90934b528736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        species|         features|species_by|\n",
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|100|          5.7|         2.8|          4.1|         1.3|Iris-versicolor|[5.7,2.8,4.1,1.3]|       1.0|\n",
      "|101|          6.3|         3.3|          6.0|         2.5| Iris-virginica|[6.3,3.3,6.0,2.5]|       2.0|\n",
      "|102|          5.8|         2.7|          5.1|         1.9| Iris-virginica|[5.8,2.7,5.1,1.9]|       2.0|\n",
      "|103|          7.1|         3.0|          5.9|         2.1| Iris-virginica|[7.1,3.0,5.9,2.1]|       2.0|\n",
      "|104|          6.3|         2.9|          5.6|         1.8| Iris-virginica|[6.3,2.9,5.6,1.8]|       2.0|\n",
      "|105|          6.5|         3.0|          5.8|         2.2| Iris-virginica|[6.5,3.0,5.8,2.2]|       2.0|\n",
      "|107|          4.9|         2.5|          4.5|         1.7| Iris-virginica|[4.9,2.5,4.5,1.7]|       2.0|\n",
      "|108|          7.3|         2.9|          6.3|         1.8| Iris-virginica|[7.3,2.9,6.3,1.8]|       2.0|\n",
      "|110|          7.2|         3.6|          6.1|         2.5| Iris-virginica|[7.2,3.6,6.1,2.5]|       2.0|\n",
      "|111|          6.5|         3.2|          5.1|         2.0| Iris-virginica|[6.5,3.2,5.1,2.0]|       2.0|\n",
      "|112|          6.4|         2.7|          5.3|         1.9| Iris-virginica|[6.4,2.7,5.3,1.9]|       2.0|\n",
      "|114|          5.7|         2.5|          5.0|         2.0| Iris-virginica|[5.7,2.5,5.0,2.0]|       2.0|\n",
      "|115|          5.8|         2.8|          5.1|         2.4| Iris-virginica|[5.8,2.8,5.1,2.4]|       2.0|\n",
      "|117|          6.5|         3.0|          5.5|         1.8| Iris-virginica|[6.5,3.0,5.5,1.8]|       2.0|\n",
      "|118|          7.7|         3.8|          6.7|         2.2| Iris-virginica|[7.7,3.8,6.7,2.2]|       2.0|\n",
      "|119|          7.7|         2.6|          6.9|         2.3| Iris-virginica|[7.7,2.6,6.9,2.3]|       2.0|\n",
      "|120|          6.0|         2.2|          5.0|         1.5| Iris-virginica|[6.0,2.2,5.0,1.5]|       2.0|\n",
      "|121|          6.9|         3.2|          5.7|         2.3| Iris-virginica|[6.9,3.2,5.7,2.3]|       2.0|\n",
      "|122|          5.6|         2.8|          4.9|         2.0| Iris-virginica|[5.6,2.8,4.9,2.0]|       2.0|\n",
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "34104267-1a91-4983-97d5-4fd593b85912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = dt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36930349-9fe1-4088-ae2e-a24e625b6800",
   "metadata": {},
   "source": [
    "#### Ver las 5 primeras predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f71a9af7-a23d-4dce-b889-1df4839b7bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+--------------+-----------------+----------+--------------+-------------+----------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|       species|         features|species_by| rawPrediction|  probability|prediction|\n",
      "+---+-------------+------------+-------------+------------+--------------+-----------------+----------+--------------+-------------+----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|   Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|[33.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|106|          7.6|         3.0|          6.6|         2.1|Iris-virginica|[7.6,3.0,6.6,2.1]|       2.0|[0.0,0.0,33.0]|[0.0,0.0,1.0]|       2.0|\n",
      "|109|          6.7|         2.5|          5.8|         1.8|Iris-virginica|[6.7,2.5,5.8,1.8]|       2.0|[0.0,0.0,33.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|   Iris-setosa|[5.4,3.7,1.5,0.2]|       0.0|[33.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|113|          6.8|         3.0|          5.5|         2.1|Iris-virginica|[6.8,3.0,5.5,2.1]|       2.0|[0.0,0.0,33.0]|[0.0,0.0,1.0]|       2.0|\n",
      "+---+-------------+------------+-------------+------------+--------------+-----------------+----------+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08f59c-e31a-433e-9afe-b0e4aacb9c42",
   "metadata": {},
   "source": [
    "## Ver la precisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0592ee08-2357-48cb-a97a-67d9bfe9d56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='species_by',\n",
    "                                              predictionCol='prediction',\n",
    "                                              metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print('Test Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a27579fc-77af-46ab-a4d1-f68db1556271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "| id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        species|         features|species_by|\n",
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|    Iris-setosa|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|100|          5.7|         2.8|          4.1|         1.3|Iris-versicolor|[5.7,2.8,4.1,1.3]|       1.0|\n",
      "|101|          6.3|         3.3|          6.0|         2.5| Iris-virginica|[6.3,3.3,6.0,2.5]|       2.0|\n",
      "|102|          5.8|         2.7|          5.1|         1.9| Iris-virginica|[5.8,2.7,5.1,1.9]|       2.0|\n",
      "|103|          7.1|         3.0|          5.9|         2.1| Iris-virginica|[7.1,3.0,5.9,2.1]|       2.0|\n",
      "|104|          6.3|         2.9|          5.6|         1.8| Iris-virginica|[6.3,2.9,5.6,1.8]|       2.0|\n",
      "|105|          6.5|         3.0|          5.8|         2.2| Iris-virginica|[6.5,3.0,5.8,2.2]|       2.0|\n",
      "|107|          4.9|         2.5|          4.5|         1.7| Iris-virginica|[4.9,2.5,4.5,1.7]|       2.0|\n",
      "|108|          7.3|         2.9|          6.3|         1.8| Iris-virginica|[7.3,2.9,6.3,1.8]|       2.0|\n",
      "|110|          7.2|         3.6|          6.1|         2.5| Iris-virginica|[7.2,3.6,6.1,2.5]|       2.0|\n",
      "|111|          6.5|         3.2|          5.1|         2.0| Iris-virginica|[6.5,3.2,5.1,2.0]|       2.0|\n",
      "|112|          6.4|         2.7|          5.3|         1.9| Iris-virginica|[6.4,2.7,5.3,1.9]|       2.0|\n",
      "|114|          5.7|         2.5|          5.0|         2.0| Iris-virginica|[5.7,2.5,5.0,2.0]|       2.0|\n",
      "|115|          5.8|         2.8|          5.1|         2.4| Iris-virginica|[5.8,2.8,5.1,2.4]|       2.0|\n",
      "|117|          6.5|         3.0|          5.5|         1.8| Iris-virginica|[6.5,3.0,5.5,1.8]|       2.0|\n",
      "|118|          7.7|         3.8|          6.7|         2.2| Iris-virginica|[7.7,3.8,6.7,2.2]|       2.0|\n",
      "|119|          7.7|         2.6|          6.9|         2.3| Iris-virginica|[7.7,2.6,6.9,2.3]|       2.0|\n",
      "|120|          6.0|         2.2|          5.0|         1.5| Iris-virginica|[6.0,2.2,5.0,1.5]|       2.0|\n",
      "|121|          6.9|         3.2|          5.7|         2.3| Iris-virginica|[6.9,3.2,5.7,2.3]|       2.0|\n",
      "|122|          5.6|         2.8|          4.9|         2.0| Iris-virginica|[5.6,2.8,4.9,2.0]|       2.0|\n",
      "+---+-------------+------------+-------------+------------+---------------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35dcf60-51d5-40cf-a770-e7b6b9abe3aa",
   "metadata": {},
   "source": [
    "# Calcular la predicción y la precisión del modelo empleando Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2027f254-a8df-4942-9281-e5015659e054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+----------+--------------------+----------+--------------------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|species_by|       rawPrediction|prediction|         probability|\n",
      "+-------------+------------+-------------+------------+----------+--------------------+----------+--------------------+\n",
      "|          5.1|         3.5|          1.4|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          7.6|         3.0|          6.6|         2.1|       2.0|[0.0,0.0384615384...|       2.0|[0.0,0.0019230769...|\n",
      "|          6.7|         2.5|          5.8|         1.8|       2.0|[0.0,0.1470183711...|       2.0|[0.0,0.0073509185...|\n",
      "|          5.4|         3.7|          1.5|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          6.8|         3.0|          5.5|         2.1|       2.0|[0.0,0.0729442970...|       2.0|[0.0,0.0036472148...|\n",
      "|          6.4|         3.2|          5.3|         2.3|       2.0|[0.0,0.1870183711...|       2.0|[0.0,0.0093509185...|\n",
      "|          4.8|         3.4|          1.6|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          7.2|         3.2|          6.0|         1.8|       2.0|[0.0,0.0384615384...|       2.0|[0.0,0.0019230769...|\n",
      "|          6.1|         3.0|          4.9|         1.8|       2.0|[0.0,3.7115281750...|       2.0|[0.0,0.1855764087...|\n",
      "|          6.4|         2.8|          5.6|         2.1|       2.0|[0.0,0.1870183711...|       2.0|[0.0,0.0093509185...|\n",
      "|          7.2|         3.0|          5.8|         1.6|       2.0|[0.0,11.038461538...|       1.0|[0.0,0.5519230769...|\n",
      "|          6.3|         2.8|          5.1|         1.5|       2.0|[0.0,11.852535612...|       1.0|[0.0,0.5926267806...|\n",
      "|          6.3|         3.4|          5.6|         2.4|       2.0|[0.0,0.1870183711...|       2.0|[0.0,0.0093509185...|\n",
      "|          6.4|         3.1|          5.5|         1.8|       2.0|[0.0,0.1870183711...|       2.0|[0.0,0.0093509185...|\n",
      "|          5.8|         2.7|          5.1|         1.9|       2.0|[0.0,0.2703517044...|       2.0|[0.0,0.0135175852...|\n",
      "|          5.7|         3.8|          1.7|         0.3|       0.0|      [18.0,2.0,0.0]|       0.0|       [0.9,0.1,0.0]|\n",
      "|          5.4|         3.4|          1.7|         0.2|       0.0|      [18.0,2.0,0.0]|       0.0|       [0.9,0.1,0.0]|\n",
      "|          4.8|         3.4|          1.9|         0.2|       0.0|      [13.0,5.0,2.0]|       0.0|     [0.65,0.25,0.1]|\n",
      "|          5.0|         3.0|          1.6|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          4.7|         3.2|          1.6|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          4.8|         3.1|          1.6|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          5.4|         3.4|          1.5|         0.4|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          4.6|         3.1|          1.5|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|          4.5|         2.3|          1.3|         0.3|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|          4.4|         3.2|          1.3|         0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "+-------------+------------+-------------+------------+----------+--------------------+----------+--------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'species_by')\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('SepalLengthCm',\n",
    " 'SepalWidthCm',\n",
    " 'PetalLengthCm',\n",
    " 'PetalWidthCm', 'species_by', 'rawPrediction', 'prediction', 'probability').show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de0509-27f8-40b0-9a50-ad58fba2d480",
   "metadata": {},
   "source": [
    "### Ver la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7e37cf22-891d-48e6-bd70-d8c1d6a9aac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.935645173388004\n",
      "Test Error = 0.06435482661199599\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"species_by\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a904e-b4e6-41c3-a4c7-850cb94508b9",
   "metadata": {},
   "source": [
    "# Calcular la predicción y la precisión del modelo empleando Gradient-boosted tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "54a787b3-f4d9-498a-8205-a93f52782a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "# Entrenar el modelo GBT\n",
    "gbt = GBTClassifier(labelCol=\"species_by\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "78ac104c-bd45-45b4-bfa6-ce4e408b3269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SepalLengthCm', 'double'),\n",
       " ('SepalWidthCm', 'double'),\n",
       " ('PetalLengthCm', 'double'),\n",
       " ('PetalWidthCm', 'double'),\n",
       " ('features', 'vector'),\n",
       " ('species_by', 'double')]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('id')\n",
    "df = df.drop('species')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8eabeeac-bc1c-4d3f-b789-61181133de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+------------+-----------------+----------+\n",
      "|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|         features|species_by|\n",
      "+-------------+------------+-------------+------------+-----------------+----------+\n",
      "|          5.1|         3.5|          1.4|         0.2|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|          4.9|         3.0|          1.4|         0.2|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|          4.7|         3.2|          1.3|         0.2|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|          4.6|         3.1|          1.5|         0.2|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|          5.0|         3.6|          1.4|         0.2|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "|          5.4|         3.9|          1.7|         0.4|[5.4,3.9,1.7,0.4]|       0.0|\n",
      "|          4.6|         3.4|          1.4|         0.3|[4.6,3.4,1.4,0.3]|       0.0|\n",
      "|          5.0|         3.4|          1.5|         0.2|[5.0,3.4,1.5,0.2]|       0.0|\n",
      "|          4.4|         2.9|          1.4|         0.2|[4.4,2.9,1.4,0.2]|       0.0|\n",
      "|          4.9|         3.1|          1.5|         0.1|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|          5.4|         3.7|          1.5|         0.2|[5.4,3.7,1.5,0.2]|       0.0|\n",
      "|          4.8|         3.4|          1.6|         0.2|[4.8,3.4,1.6,0.2]|       0.0|\n",
      "|          4.8|         3.0|          1.4|         0.1|[4.8,3.0,1.4,0.1]|       0.0|\n",
      "|          4.3|         3.0|          1.1|         0.1|[4.3,3.0,1.1,0.1]|       0.0|\n",
      "|          5.8|         4.0|          1.2|         0.2|[5.8,4.0,1.2,0.2]|       0.0|\n",
      "|          5.7|         4.4|          1.5|         0.4|[5.7,4.4,1.5,0.4]|       0.0|\n",
      "|          5.4|         3.9|          1.3|         0.4|[5.4,3.9,1.3,0.4]|       0.0|\n",
      "|          5.1|         3.5|          1.4|         0.3|[5.1,3.5,1.4,0.3]|       0.0|\n",
      "|          5.7|         3.8|          1.7|         0.3|[5.7,3.8,1.7,0.3]|       0.0|\n",
      "|          5.1|         3.8|          1.5|         0.3|[5.1,3.8,1.5,0.3]|       0.0|\n",
      "+-------------+------------+-------------+------------+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d0635061-6b9b-41fc-a30c-4d2d69a83587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3580.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 445.0 failed 1 times, most recent failure: Lost task 0.0 in stage 445.0 (TID 393) (1349f8b13622 executor driver): java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:176)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:173)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1198)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2322)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$1(RDD.scala:1200)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1193)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:125)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:333)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:61)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$1(GBTClassifier.scala:209)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:170)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:58)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat jdk.internal.reflect.GeneratedMethodAccessor155.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:176)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:173)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1198)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2322)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Me da error nose resolverlo.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Labels must be in {0,1}; note that GBTClassifier \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# currently only supports binary classification.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Modelo:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m modelGBT \u001b[38;5;241m=\u001b[39m \u001b[43mgbt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:383\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 383\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:380\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3580.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 445.0 failed 1 times, most recent failure: Lost task 0.0 in stage 445.0 (TID 393) (1349f8b13622 executor driver): java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:176)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:173)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1198)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2322)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$1(RDD.scala:1200)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1193)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:125)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:333)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:61)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$1(GBTClassifier.scala:209)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:170)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:58)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:115)\n\tat jdk.internal.reflect.GeneratedMethodAccessor155.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\nCaused by: java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:176)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:173)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1198)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2322)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Me da error nose resolverlo.\n",
    "# Labels must be in {0,1}; note that GBTClassifier \n",
    "# currently only supports binary classification.\n",
    "# Modelo:\n",
    "modelGBT = gbt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd5e2a-959f-4632-975a-f6fae710db7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hacer predicción.\n",
    "predictionsGBT = modelGBT.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c4b81-fc8c-45bc-a8ce-7f541625ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionar filas de ejemplo para mostrar.\n",
    "predictionsGBT.select(\"prediction\", \"probability\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45f31f-21af-4cc7-a8b1-090eb78231b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"species_by\",\n",
    "predictionCol=\"prediction\",\n",
    "metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionsGBT)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead0a8c-f3c8-4ce3-a91d-10a971deaf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
